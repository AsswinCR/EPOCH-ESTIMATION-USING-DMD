
## EPOCH ESTIMATION USING DMD

üìù Project Overview

This project aims to estimate epoch or Glottal Closure Instant (GCI) locations from speech signals using Dynamic Mode Decomposition (DMD). Unlike conventional linear models, DMD models the speech production system as a non-linear system to capture instantaneous pitch frequencies from the modes of DMD, providing higher accuracy in epoch detection.



üéØ Objective
	‚Ä¢	Estimate epoch locations with higher accuracy using DMD.
	‚Ä¢	Identify the mode frequency closest to the fundamental frequency for each glottal cycle.
	‚Ä¢	Construct a sine wave from the estimated mode and extract negative-to-positive zero-crossings as epoch locations.
	‚Ä¢	Compare DMD-based epoch estimation with traditional methods such as VMD and ZFF.

‚∏ª

Key Features:
	‚Ä¢	‚úÖ Non-linear Model for Speech Production: DMD captures the non-linear interaction of the excitation signal with vocal tract responses.
	‚Ä¢	‚úÖ Accurate Epoch Estimation: Detects epoch locations with greater accuracy by choosing the dominant mode.
	‚Ä¢	‚úÖ Efficient Pipeline: Single-step DMD decomposition is computationally lighter than VMD‚Äôs iterative process.

‚∏ª

üìÇ File Structure

‚îú‚îÄ‚îÄ DMD_code_5.m                # MATLAB code for DMD-based epoch estimation
‚îú‚îÄ‚îÄ README.md                   # Project documentation
‚îú‚îÄ‚îÄ Report.docx                  # Detailed project report with results and analysis
‚îî‚îÄ‚îÄ SPEECH_DMD_FINAL.pptx       # Final presentation with methodology and results



‚∏ª

üìñ Usage Instructions

1Ô∏è‚É£ Clone the Repository

git clone https://github.com/AsswinCR/EPOCH-ESTIMATION-USING-DMD.git
cd EPOCH-ESTIMATION-USING-DMD



‚∏ª

2Ô∏è‚É£ Run the MATLAB Code
	‚Ä¢	Open DMD_code_5.m in MATLAB.
	‚Ä¢	Execute the script to process the speech signal and estimate epoch locations.
	‚Ä¢	Modify the input parameters (if needed) to experiment with different datasets.

% Run in MATLAB
DMD_code_5.m



‚∏ª

3Ô∏è‚É£ Dataset Description
	‚Ä¢	Dataset: CMU Arctic Dataset
	‚Ä¢	Details:
	‚Ä¢	1150 utterances of male and female speakers.
	‚Ä¢	US English language.
	‚Ä¢	Speech signals and EGG signals.
	‚Ä¢	Recorded at 32KHz sampling frequency with 16-bit resolution.

‚∏ª

‚öôÔ∏è Installation and Requirements

üìö Required Software
	‚Ä¢	MATLAB (R2021 or later recommended)
	‚Ä¢	Toolboxes:
	‚Ä¢	Signal Processing Toolbox
	‚Ä¢	Optimization Toolbox

‚∏ª

Step-by-Step Implementation

Step 1: Load and Preprocess the Data
	‚Ä¢	Load the speech signal and corresponding EGG signal.
	‚Ä¢	Resample both signals to 16KHz.

[y1, Fs] = audioread(path+"arctic_a0002.wav");
sp1 = y1(:,1); % Speech signal
egg1 = y1(:,2); % EGG signal
sp = resample(sp1, Fs, 16000);
egg = resample(egg1, Fs, 16000);



‚∏ª

Step 2: Apply DMD to Extract Modes
	‚Ä¢	Decompose the speech signal into different modes using DMD.
	‚Ä¢	Identify the mode frequency closest to the fundamental frequency.

% Define parameters
start_limit = 20000;
end_limit = 52000;

% Iterate through speech frames
for k = start_limit:2000:end_limit-2000
    range1 = k;
    range2 = k + 2000;
    final_mode_freq = simulate_signal(sp, egg, range1, range2, Fs);
    all_freqs = [all_freqs final_mode_freq];
end



‚∏ª

Step 3: Generate Sine Wave from Mode Frequency
	‚Ä¢	Construct a sine wave based on the estimated mode frequency.
	‚Ä¢	Combine sine waves from all speech frames to form the simulated excitation signal.

% Generate sine wave using mode frequency
fs = 16000;
dt = 1/fs;
StopTime = ((62.5 * 2 * length(all_freqs)) / 1000);
t = (0:dt:StopTime)';
data_all = [];

for i = 1:length(all_freqs)
    final_mode_freq = all_freqs(i);
    data = find_sine(final_mode_freq);
    data_all = [data_all; data];
end

data_all = data_all(1:length(data_all)-length(all_freqs)+1);



‚∏ª
Step 4: Epoch Estimation
	‚Ä¢	Identify epoch locations from the zero-crossings of the sine wave.
	‚Ä¢	Compare epoch locations with the DEGG signal to validate accuracy.

% Plot DEGG and sine wave to visualize epoch locations
figure;
egg_part = egg(start_limit:end_limit);
plot(diff(egg_part));
hold on;
plot(t * 100000 / 6.25, data_all);



‚∏ª

Step 5: Mode Frequency Estimation using DMD
	‚Ä¢	Apply DMD to speech frames to estimate dominant mode frequencies.
	‚Ä¢	Identify modes that align closely with the fundamental frequency.

function [final_mode_freq] = simulate_signal(sp, egg, range1, range2, Fs)
    sp = sp(range1:range2-1);
    egg = egg(range1:range2-1);

    % Apply DMD and estimate mode frequency
    [X1, X2] = DMD_v2(sp, 200);
    [mode_freq] = get_freq(X1, X2, Fs);
    final_mode_freq = mode_freq;
end



‚∏ª

üìä Results and Discussion

‚úÖ Experimental Setup
	‚Ä¢	Dataset: CMU Arctic Dataset with 1150 utterances of male and female speakers.
	‚Ä¢	Sampling Frequency: 32KHz (downsampled to 16KHz).
	‚Ä¢	Validation: Comparison with ground truth EGG signals.

‚∏ª

üìà Observations
	‚Ä¢	DMD accurately identifies mode frequencies closer to the fundamental frequency.
	‚Ä¢	Estimated epoch locations closely resemble the DEGG signal‚Äôs negative peaks.
	‚Ä¢	Computational complexity reduced compared to iterative VMD methods.

‚∏ª

üé• Visualizations
	‚Ä¢	Epoch locations plotted alongside DEGG signals to validate accuracy.
	‚Ä¢	Multiple speech frames concatenated to visualize complete speech signals.

‚∏ª

ü§ù Contribution Guidelines

Contributions, improvements, and suggestions are welcome!
To contribute:
	1.	Fork the repository.
	2.	Create a new branch (feature/your-feature).
	3.	Commit your changes.
	4.	Submit a pull request.

‚∏ª

üß© License
This project is licensed under the MIT License.

‚∏ª

üóÇÔ∏è References
	‚Ä¢	Karam, Zahi N., et al. ‚ÄúEcologically valid long-term mood monitoring using speech.‚Äù ICASSP 2014.
	‚Ä¢	Naylor, P.A., et al. ‚ÄúEstimation of glottal closure instants in voiced speech using the DYPSA algorithm.‚Äù IEEE 2007.
	‚Ä¢	Dragomiretskiy, K., Zosso, D. ‚ÄúVariational mode decomposition.‚Äù IEEE Transactions 2014.


